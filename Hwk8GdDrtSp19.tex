\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={BTRY 3020/STSCI 3200: Homework VIII},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{BTRY 3020/STSCI 3200: Homework VIII}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\section{NAME: Kevin Klaben}\label{name-kevin-klaben}

\section{NETID: kek228}\label{netid-kek228}

\section{\texorpdfstring{\textbf{DUE DATE: 8:40 am Tuesday April 30,
2019}}{DUE DATE: 8:40 am Tuesday April 30, 2019}}\label{due-date-840-am-tuesday-april-30-2019}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\section{Question 1.}\label{question-1.}

An experiment was conducted to determine the effects of four medicines
in combination with levels sodium intake on blood pressure. The
medications included three new medications that were assumed to reduce
blood pressure using a new, unique biological approach, while the fourth
was the most commonly used medication at that time. The first three
medications were the new ones, and are labelled M1, M2, and M3, while
the last, currently used medication was labelled M4. Sodium levels were
S1, where no additional sodium (salt) was added to the patient's food,
while the other was S2, where patients used sodium (salt) normally.

Each combination of medication and sodium level was randomly assigned
ten patients, and each patient followed their medication-sodium regiment
for a month, to allow time for the medications to take effect. Blood
pressure was then measured on each patient once a day for the next ten
days. This resulted in a total of 800 records of blood pressure.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\tightlist
\item
  What are the experimental factors in this study? What is the
  experimental design?
\end{enumerate}

The experimental factors sodium intake and medicine. The design for this
experiment is a completely randomized design in which patients were
randomly evenly split amoungst the 8 treatment groups.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  What are the experimental treatments in this study? Explain in one
  sentence. How many are there?
\end{enumerate}

There a total of 8 treatment groups, as there are four levels of
medication and 2 levels of sodium intake. Patients are randomly assigned
a medicine to take and a sodium intake amoutn resulting in 8 total
treatment groups.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  What are the experimental units in this study? Explain in one
  sentence.
\end{enumerate}

The experimental units are the people with high blood pressure being
assigned to treatment groups.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  How many replicates are there for each treatment? Explain in one
  sentence.
\end{enumerate}

There are 10 replicates for each treatment, as there are ten patients
assigned to each treatment.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  What are the sampling units in this study? Explain in one sentence.
\end{enumerate}

The sampling units are blood pressure measures taken of each person in
each treatment group 10 times resulting in 800 total samples.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Are pseudoreplicates present in this study? Explain in one sentence.
  How would these be used in the analysis of treatment effects?
\end{enumerate}

Yes, pseudoreplication is present, the fact that we are taking 10 data
points from each patient is pseudoreplication as it yield an
artificially high number of observations whihc will not indicate the
same strength of confidence in our conclusion as would 800 different
patients each having their blood pressure taken once. In the analysis,
we could take this into account by instead of using each sample taken as
a separate observation, instead take the average of ten observations per
patients and analyze suing these averages.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  If you wanted to compare each of the new medicines with the currently
  used one, which technique would you use? What would allow you to make
  this comparison while ignoring the sodium levels?
\end{enumerate}

This can be done by using dunnett's method, as it can be used to compare
all other treatments with a control. We would need to see that different
sodium levels had no significant impact on the blood pressures, then we
would be able to ignore the sodium levels.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Let \(\mu_{ij}\) be the mean reduction in blood pressure for the ith
  medicine at the jth sodium level, i = 1, 2, 3, 4; j = 1, 2. Construct
  a contrast that compares the medicines using the new biological
  approach to the currently used medicine.
\end{enumerate}

The contrast would be
(\(\mu_{1,1}\)+\(\mu_{2,1}\)+\(\mu_{3,1}\)+\(\mu_{1,2}\)+\(\mu_{2,2}\)+\(\mu_{3,2}\))/6-(\(\mu_{4,1}\)+\(\mu_{4,2}\))/2.

\pagebreak

\section{Question 2.}\label{question-2.}

An experiment was run to study how long mung bean seeds should be soaked
prior to planting in order to promote early growth of bean sprouts. The
experiment was run using a completely randomized design. Soaking levels
used in this experiment were as follows: A= low, B= medium, C = high,
and D = very high. For each treatment level, 17 beans were used and the
mean shoot length (Y in mm) was measured 48 hours following soaking.
Data appears in the file Hwk8Q2DatSp19.xlsx.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\tightlist
\item
  Perform analysis of variance to test the hypothesis that the four
  treatments' means are equal. State carefully your conclusions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readxl)}
\NormalTok{BeanDat <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"Hwk8Q2DatSp19.xlsx"}\NormalTok{) }
\NormalTok{BeanDat}\OperatorTok{$}\NormalTok{Treatment <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(BeanDat}\OperatorTok{$}\NormalTok{Treatment) }
\NormalTok{Bean.aov <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(Length }\OperatorTok{~}\StringTok{ }\NormalTok{Treatment, }\DataTypeTok{data =}\NormalTok{ BeanDat) }
\KeywordTok{summary}\NormalTok{(Bean.aov)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             Df Sum Sq Mean Sq F value Pr(>F)    
## Treatment    3 2501.3   833.8   75.92 <2e-16 ***
## Residuals   64  702.8    11.0                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The overall F-Test in ANOVA is testing Ho:μ1 =μ2 = \ldots{}=μ4 vs
Ha:NotHo As we saw with the regression, the F-Test has test statistic
75.92 on 3 and 64 df, with an extremely small p-value, we reject the
null hypothesis and conclude that at least one mean is not equal to
zero.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Give a statistical model appropriate for describing the response
  variable in this study and explain each term in the model.
\end{enumerate}

the model would be: \(y_{ij}\)=\(\mu_{i}\)+\(\epsilon_{ij}\) where
\(y_{ij}\) is normally distributed N(\(\mu_{i}\),\(\sigma^2\))
\(\mu{i}\) is the theoretical mean of all observations at factor level i
\(\epsilon{ij}\) is the jth error term of observation \(y_{ij}\)

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Assess the validity of assumptions underlying analysis of variance in
  this study.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bean.lm <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Length }\OperatorTok{~}\StringTok{ }\NormalTok{Treatment, }\DataTypeTok{data=}\NormalTok{BeanDat)}
\KeywordTok{library}\NormalTok{(car)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: carData
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{StdResids<-}\KeywordTok{rstandard}\NormalTok{(Bean.lm) }
\NormalTok{Fits<-}\KeywordTok{fitted.values}\NormalTok{(Bean.lm)}
\KeywordTok{plot}\NormalTok{(Fits, StdResids, }\DataTypeTok{main=}\StringTok{"Residual Plot for Bean Growth ANOVA"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hwk8GdDrtSp19_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qqPlot}\NormalTok{(StdResids, }\DataTypeTok{main=}\StringTok{"QQPlot for Wait Ratings ANOVA"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Hwk8GdDrtSp19_files/figure-latex/unnamed-chunk-2-2.pdf}

\begin{verbatim}
## [1] 18 41
\end{verbatim}

Assumptions: 1) Independence: guaranteed by random assignment of
treatments to beans (experimental units); 2) Normality: qqPlot looks
good enough (linear models' procedures are robust against
non-normality); 3) Linearity: Not really an assumption since all
predictors are categorical 4) Constant variance: Looks fine in residual
plot 5) Outliers not driving conclusions: No outliers apparent in either
diagnostic plot.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{3}
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Compare all pairs of means, using Bonferoni's method and make an
    interpretation of your results. Use \(\alpha_{overall}\) = .05.
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{with}\NormalTok{(BeanDat,}\KeywordTok{pairwise.t.test}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Length, }\DataTypeTok{g=}\NormalTok{Treatment, }\DataTypeTok{p.adjust=}\StringTok{"bonferroni"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Length and Treatment 
## 
##   A       B     C    
## B 1.4e-15 -     -    
## C < 2e-16 1.000 -    
## D < 2e-16 0.082 0.753
## 
## P value adjustment method: bonferroni
\end{verbatim}

We see very low p-values for comparing low to medium, low to high, and
low to very high, thus these are the signifcant differences in thier
means in our results. ii) What are the advantages and disadvantages of
using this method of pairwise comparisons?

Bonferroni controls \(\alpha_{overall}\) precisely but it is not as
powerful as tukey's for all pairwise comparisons.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{4}
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Compare all pairs of means, using Tukey's method and make an
    interpretation of your results. Use \(\alpha_{overall}\) = .05.
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{TukeyHSD}\NormalTok{(Bean.aov)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Length ~ Treatment, data = BeanDat)
## 
## $Treatment
##          diff        lwr       upr     p adj
## B-A 12.470588  9.4723100 15.468866 0.0000000
## C-A 13.588235 10.5899571 16.586513 0.0000000
## D-A 15.352941 12.3546630 18.351219 0.0000000
## C-B  1.117647 -1.8806311  4.115925 0.7594325
## D-B  2.882353 -0.1159253  5.880631 0.0638738
## D-C  1.764706 -1.2335723  4.762984 0.4128068
\end{verbatim}

We see very low p-values for comparing low to medium, low to high, and
low to very high, thus these are the signifcant differences in thier
means in our results. ii) What are the advantages and disadvantages of
using this method of pairwise comparisons?

Most powerful procedure for comparing means pairwise while controlling
for \(\alpha_{overall}\) absolutely.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{5}
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Compare all pairs of means, using Fisher's Protected LSD and make an
    interpretation of your results. Use \(\alpha_{overall}\) = .05.
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{with}\NormalTok{(BeanDat, }\KeywordTok{pairwise.t.test}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Length, }\DataTypeTok{g=}\NormalTok{Treatment, }\DataTypeTok{p.adjust=}\StringTok{"none"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Length and Treatment 
## 
##   A       B     C    
## B 2.4e-16 -     -    
## C < 2e-16 0.329 -    
## D < 2e-16 0.014 0.125
## 
## P value adjustment method: none
\end{verbatim}

We see very low p-values for comparing low to medium, low to high, and
low to very high as well as medium to very high, thus these are the
signifcant differences in thier means in our results. ii) What are the
advantages and disadvantages of using this method of pairwise
comparisons? Fisher's is easy to use and more powerful than Tukey's and
scheffe's methods while it does have the draw back of only approximately
controlling \(\alpha_{overall}\) and it can't be used when the overall
F-test fails to reject.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Consider the first two levels (low, medium) as ``short'' soaking
  periods and the two higher levels (High, very high) as ``long''
  soaking periods. You want to determine the difference in mean sprout
  length between the short and long soaking periods.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{aggregate}\NormalTok{(Length }\OperatorTok{~}\StringTok{ }\NormalTok{Treatment, }\DataTypeTok{data=}\NormalTok{BeanDat, mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Treatment    Length
## 1         A  5.941176
## 2         B 18.411765
## 3         C 19.529412
## 4         D 21.294118
\end{verbatim}

\begin{verbatim}
i) Give a 90% confidence interval for the difference in mean sprout length between short and long soaking periods. 
\end{verbatim}

L=(\(\mu{A}\)+\(\mu{B}\))/2-(\(\mu{C}\)+\(\mu{D}\))/2

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\FloatTok{5.94}\OperatorTok{+}\FloatTok{18.41}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\OperatorTok{-}\NormalTok{(}\FloatTok{19.53}\OperatorTok{+}\FloatTok{21.29}\NormalTok{)}\OperatorTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -8.235
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(Bean.aov)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             Df Sum Sq Mean Sq F value Pr(>F)    
## Treatment    3 2501.3   833.8   75.92 <2e-16 ***
## Residuals   64  702.8    11.0                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(}\FloatTok{11.0}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{4}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{4}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{4}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{4}\NormalTok{)}\OperatorTok{/}\DecValTok{17}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8043997
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{-}\FloatTok{8.235}\OperatorTok{+}\FloatTok{1.669}\OperatorTok{*}\NormalTok{(}\FloatTok{0.804}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -6.893124
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{-}\FloatTok{8.235}\OperatorTok{-}\FloatTok{1.669}\OperatorTok{*}\NormalTok{(}\FloatTok{0.804}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -9.576876
\end{verbatim}

L(hat)=(5.94+18.41)/2-(19.53+21.29)/2=-8.235
SE(L(hat))=Sqrt(11.0\emph{(1/4+1/4+1/4+1/4)/17)= 0.804
CI=-8.235+/-(0.804)}\(t_{64,0.05}\)=-8.235+/-1.669x(0.804)=(-6.89,-9.58)
We are 90\% confident that the average mung bean sprout is 6.89 to 9.58
millimeters shorter when soaking for shorter periods than for longer
periods. ii) Test to see if the long soaking periods produce higher mean
sprout length than the short periods, using \(\alpha\) = .05. State
hypotheses, test statistic, p-value, and conclusions. Ho:
(\(\mu{A}\)+\(\mu{B}\))/2-(\(\mu{C}\)+\(\mu{D}\))/2=0 Ha:
(\(\mu{A}\)+\(\mu{B}\))/2-(\(\mu{C}\)+\(\mu{D}\))/2\textless{}0
L=(\(\mu{A}\)+\(\mu{B}\))/2-(\(\mu{C}\)+\(\mu{D}\))/2
TS=-8.235-0/0.804=-10.24 p=P(\(t_{64}\)\textless{}-10.24)=2.054723e-15

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\OperatorTok{-}\FloatTok{8.235}\OperatorTok{-}\DecValTok{0}\NormalTok{)}\OperatorTok{/}\FloatTok{0.804}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -10.24254
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pt}\NormalTok{(}\OperatorTok{-}\FloatTok{10.24}\NormalTok{,}\DecValTok{64}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.054723e-15
\end{verbatim}

As p=2.054723e-15\textless{}alpha=0.05 we reject the null hypothesis and
conclude that long soaking periods produce higher mean lengths than
shorter soaking periods. H) Using the values corresponding to the levels
of the treatments: A = 12 hours, B= 18 hours, C = 24 hours, and D = 30
hours,

\begin{verbatim}
i) Fit a polynomial regression in hours to this data; report what you get and how you got there (show all steps and tests).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readxl)}
\NormalTok{BeanDat2 <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"Hwk8Q2part2.xlsx"}\NormalTok{)}
\NormalTok{Bean3.lm=}\KeywordTok{lm}\NormalTok{(Length}\OperatorTok{~}\NormalTok{Treatment2}\OperatorTok{+}\KeywordTok{I}\NormalTok{(Treatment2}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\KeywordTok{I}\NormalTok{(Treatment2}\OperatorTok{^}\DecValTok{3}\NormalTok{)}\OperatorTok{+}\KeywordTok{I}\NormalTok{(Treatment2}\OperatorTok{^}\DecValTok{4}\NormalTok{), }\DataTypeTok{data=}\NormalTok{BeanDat2)}
\KeywordTok{summary}\NormalTok{(Bean3.lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Length ~ Treatment2 + I(Treatment2^2) + I(Treatment2^3) + 
##     I(Treatment2^4), data = BeanDat2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.4118 -2.0294 -0.4118  2.0588  6.4706 
## 
## Coefficients: (1 not defined because of singularities)
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     -1.011e+02  2.188e+01  -4.619 1.91e-05 ***
## Treatment2       1.548e+01  3.497e+00   4.426 3.82e-05 ***
## I(Treatment2^2) -6.577e-01  1.751e-01  -3.756 0.000375 ***
## I(Treatment2^3)  9.259e-03  2.773e-03   3.339 0.001407 ** 
## I(Treatment2^4)         NA         NA      NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.314 on 64 degrees of freedom
## Multiple R-squared:  0.7806, Adjusted R-squared:  0.7704 
## F-statistic: 75.92 on 3 and 64 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bean2.lm=}\KeywordTok{lm}\NormalTok{(Length}\OperatorTok{~}\NormalTok{Treatment2}\OperatorTok{+}\KeywordTok{I}\NormalTok{(Treatment2}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\KeywordTok{I}\NormalTok{(Treatment2}\OperatorTok{^}\DecValTok{3}\NormalTok{), }\DataTypeTok{data=}\NormalTok{BeanDat2)}
\KeywordTok{summary}\NormalTok{(Bean2.lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Length ~ Treatment2 + I(Treatment2^2) + I(Treatment2^3), 
##     data = BeanDat2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.4118 -2.0294 -0.4118  2.0588  6.4706 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     -1.011e+02  2.188e+01  -4.619 1.91e-05 ***
## Treatment2       1.548e+01  3.497e+00   4.426 3.82e-05 ***
## I(Treatment2^2) -6.577e-01  1.751e-01  -3.756 0.000375 ***
## I(Treatment2^3)  9.259e-03  2.773e-03   3.339 0.001407 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.314 on 64 degrees of freedom
## Multiple R-squared:  0.7806, Adjusted R-squared:  0.7704 
## F-statistic: 75.92 on 3 and 64 DF,  p-value: < 2.2e-16
\end{verbatim}

Our final polynomial has up to cubic terms as this is the first in which
all terms are significant.
Y=-101.1+15.48(x)-0.6577(\(x^2\))+0.009259(\(x^3\))

\begin{verbatim}
ii) Compare the MSE you got from using the treatments as categorical predictors and the polynoimial predictors; assess how much explained variation you lost by forcing the means to follow the regression "line" compared to letting them "float". 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{anova}\NormalTok{(Bean.aov)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Length
##           Df  Sum Sq Mean Sq F value    Pr(>F)    
## Treatment  3 2501.29  833.76  75.924 < 2.2e-16 ***
## Residuals 64  702.82   10.98                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{anova}\NormalTok{(Bean2.lm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Length
##                 Df  Sum Sq Mean Sq F value    Pr(>F)    
## Treatment2       1 1891.78 1891.78 172.268 < 2.2e-16 ***
## I(Treatment2^2)  1  487.12  487.12  44.358 7.317e-09 ***
## I(Treatment2^3)  1  122.40  122.40  11.146  0.001407 ** 
## Residuals       64  702.82   10.98                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The MSE's are the same between the two models as the residual sum of
squares are equal between the two models. Thus, as the residual sum of
squares are equal, we conclude that no explained variation was lost as a
result of forcing the regression ``line''.

\begin{verbatim}
iii) What mean sprout length could you expect for 15 hours of soaking (use a 95% interval). Could you have gotten this by using the treatments as categorical predictors?
\end{verbatim}

pt est+/- \(t_{0.025,64}\) (SE) =

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Treatment2=}\DecValTok{15}\NormalTok{, }\DataTypeTok{Treatment2Sq=}\DecValTok{15}\OperatorTok{^}\DecValTok{2}\NormalTok{, }\DataTypeTok{Treatment2Cub=}\DecValTok{15}\OperatorTok{^}\DecValTok{3}\NormalTok{)}
\KeywordTok{predict}\NormalTok{(Bean2.lm, dat, }\DataTypeTok{se.fit=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{interval=}\StringTok{"confidence"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $fit
##        fit      lwr      upr
## 1 14.34559 12.67842 16.01276
## 
## $se.fit
## [1] 0.8345325
## 
## $df
## [1] 64
## 
## $residual.scale
## [1] 3.313852
\end{verbatim}

We can be 95\% confident that the expected bean sprount length for 15
hours of soaking will be on average between 12.6784 and 16.0128
millimeters.

No, you can't know where 15 hour would have fit in among catagorical
predictors and thus we would have no way of making this calcuation.
\pagebreak

\section{Question 3.}\label{question-3.}

For newly planted strawberries, the development of flower clusters
decreases the plant vigor. It is common practice to remove the flower
stalks by hand, but this is a laborious and time-consuming procedure. To
investigate the effect of flower clusters on the plant vigor, an
experiment consisting of four treatments was conducted. This experiment
was completely randomized and consisted of the following treatments: A =
Control (no flower removal), B = Hand removal, C = Regulator G1, and D =
Regulator G2 (note that G1 and G2 are hormone-based regulators). A plot
of 10 plants was treated and the average number of runners per mother
plant, a measure of vigor, was recorded on each plot.

The layout of the experiment and the measures of vigor are provided
below for each plot.

C. 3.6 (plot 1) A. 1.4 (plot 6) A. 0.8 (plot 11) B. 5.2 (plot 16)

C. 2.4 (plot 2) D. 7.3 (plot 7) B. 6.8 (plot 12) C. 1.8 (plot 17)

A. 0.6 (plot 3) C. 4.6 (plot 8) B. 3.0 (plot 13) D.6.2 (plot 18)

D. 3.8 (plot 4) D. 4.1 (plot 9) A. 1.2 (plot 14) B. 5.0 (plot 19)

B. 6.0 (plot 5) B. 4.0 (plot 10) A. 0.5 (plot 15) A. 1.5 (plot 20)

Note: This data set is not provided, so you need to create it.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\tightlist
\item
  Construct a set of 3 contrasts that are suggested by the treatment
  structure in this experiment to be orthogonal.
\end{enumerate}

removal vs no removal:

hand removal vs regulator removal:

g1 regulator vs G2 regulator:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readxl)}
\NormalTok{PlantDat <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"plantvigordat.xlsx"}\NormalTok{)}
\NormalTok{PlantDat}\OperatorTok{$}\NormalTok{treatment <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(PlantDat}\OperatorTok{$}\NormalTok{treatment)}
\NormalTok{contrvnr=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{,}\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{, }\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\NormalTok{conthvreg=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\OperatorTok{-}\NormalTok{.}\DecValTok{5}\NormalTok{, }\OperatorTok{-}\NormalTok{.}\DecValTok{5}\NormalTok{)}
\NormalTok{contg1vg2=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, }\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\NormalTok{cons=}\KeywordTok{cbind}\NormalTok{(contrvnr,conthvreg, contg1vg2)}

\KeywordTok{rownames}\NormalTok{(cons)}\OperatorTok{<=}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## logical(0)
\end{verbatim}

The sum of the contrasts sums of squares is 62.585 and the treatment
sums of squares is 65.33. This is

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Verbally define each of the three contrasts above.
\end{enumerate}

Our first contrast is removal vs no removal. Thus we will contrast A
with B,C, and D.

Our second contrast is hand removal vs regulator removal. Thus we will
contrast B with C and D.

Our third contrast is G1 regulator vs G2 regulator. Thus, we will
contrast C with D.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Using the contrasts in a, assess the statistical significance of each
  contrast based on p-values from an appropriate test.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(cons) }\OperatorTok{%*%}\StringTok{ }\NormalTok{cons}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           contrvnr conthvreg contg1vg2
## contrvnr  1.333333       0.0         0
## conthvreg 0.000000       1.5         0
## contg1vg2 0.000000       0.0         2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{contrasts}\NormalTok{(PlantDat}\OperatorTok{$}\NormalTok{treatment) =}\StringTok{ }\NormalTok{cons}
\CommentTok{#Now run your ANOVA}
\NormalTok{plant.lm<-}\KeywordTok{lm}\NormalTok{(vigor}\OperatorTok{~}\KeywordTok{C}\NormalTok{(treatment,contrvnr,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,conthvreg,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,contg1vg2,}\DecValTok{1}\NormalTok{), }\DataTypeTok{data=}\NormalTok{PlantDat)}
\KeywordTok{Anova}\NormalTok{(plant.lm, }\DataTypeTok{type=}\StringTok{"III"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type III tests)
## 
## Response: vigor
##                             Sum Sq Df  F value    Pr(>F)    
## (Intercept)                250.563  1 171.6920 5.697e-10 ***
## C(treatment, contrvnr, 1)   50.401  1  34.5361 2.340e-05 ***
## C(treatment, conthvreg, 1)   2.059  1   1.4111   0.25221    
## C(treatment, contg1vg2, 1)  10.125  1   6.9379   0.01805 *  
## Residuals                   23.350 16                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aov.cons <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(vigor }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ PlantDat)}
\CommentTok{#Good Luck following this next funky command to get the proper ANOVA table with the orthogonal contrasts included!}
\CommentTok{#Note the second list names your contrasts in the order you entered them into Cons}
\end{Highlighting}
\end{Shaded}

As we can see from the anova table, only the signifcant contrasts are
removal vs non-removal with a p-value on an F-test of 2.340e-05, and
similarly, the contrast of the G1 regulator vs G2 regulator with a
p-value of 0.01805.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Demonstrate that the three contrast sums of squares do not add up to
  the treatment sum of squares (there is more than one way to do this).
  Are you surprised by your results? Why or why not? Are these contrasts
  orthogonal? Why or why not?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(cons) }\OperatorTok{%*%}\StringTok{ }\NormalTok{cons}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           contrvnr conthvreg contg1vg2
## contrvnr  1.333333       0.0         0
## conthvreg 0.000000       1.5         0
## contg1vg2 0.000000       0.0         2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{contrasts}\NormalTok{(PlantDat}\OperatorTok{$}\NormalTok{treatment) =}\StringTok{ }\NormalTok{cons}
\CommentTok{#Now run your ANOVA}
\NormalTok{plant.lm<-}\KeywordTok{lm}\NormalTok{(vigor}\OperatorTok{~}\KeywordTok{C}\NormalTok{(treatment,contrvnr,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,conthvreg,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,contg1vg2,}\DecValTok{1}\NormalTok{), }\DataTypeTok{data=}\NormalTok{PlantDat)}
\KeywordTok{Anova}\NormalTok{(plant.lm, }\DataTypeTok{type=}\StringTok{"III"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type III tests)
## 
## Response: vigor
##                             Sum Sq Df  F value    Pr(>F)    
## (Intercept)                250.563  1 171.6920 5.697e-10 ***
## C(treatment, contrvnr, 1)   50.401  1  34.5361 2.340e-05 ***
## C(treatment, conthvreg, 1)   2.059  1   1.4111   0.25221    
## C(treatment, contg1vg2, 1)  10.125  1   6.9379   0.01805 *  
## Residuals                   23.350 16                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aov.cons <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(vigor }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ PlantDat)}
\CommentTok{#Good Luck following this next funky command to get the proper ANOVA table with the orthogonal contrasts included!}
\CommentTok{#Note the second list names your contrasts in the order you entered them into Cons}
\KeywordTok{summary}\NormalTok{(aov.cons, }\DataTypeTok{split=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{treatment=}\KeywordTok{list}\NormalTok{(}\StringTok{"no removal vs removal"}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{"hand vs regulator"}\NormalTok{=}\DecValTok{2}\NormalTok{,}\StringTok{"g1 vs g2"}\NormalTok{=}\DecValTok{3}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"III"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                    Df Sum Sq Mean Sq F value   Pr(>F)    
## treatment                           3  65.33   21.78  14.921 6.75e-05 ***
##   treatment: no removal vs removal  1  53.14   53.14  36.415 1.74e-05 ***
##   treatment: hand vs regulator      1   2.06    2.06   1.411    0.252    
##   treatment: g1 vs g2               1  10.13   10.13   6.938    0.018 *  
## Residuals                          16  23.35    1.46                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{50.401}\OperatorTok{+}\FloatTok{2.059}\OperatorTok{+}\FloatTok{10.125}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 62.585
\end{verbatim}

The sum of squares of the the contrast do not add to the sum of squares
of treatment as 50.401+2.059+10.125=62.585 which does not equal the sum
of squares of treatment which canbe seen to be 65.33. This is not
surprising as our treatment groups are of different size. The fact that
the groups are not equal also means that they will not be orthogonal.

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Remove the observations for plots 5, 10, 15, and 20. Re-compute the
  treatment and contrast sums of squares. Demonstrate that the three
  contrast sums of squares add up to the treatment sum of squares. Are
  you surprised by your results? Why or why not? Construct an ANOVA
  table which shows that with this balanced design, the sums of squares
  for treatments partitions into the sums of squares for the three
  contrasts. Are these contrasts now orthogonal? Why or why not?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test <-}\StringTok{ }\NormalTok{ChickWeight[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{578}\NormalTok{),]}

\KeywordTok{library}\NormalTok{(readxl)}
\NormalTok{PlantDat2 <-}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}\StringTok{"plantvigordat.xlsx"}\NormalTok{)}
\NormalTok{PlantDat2 <-}\StringTok{ }\NormalTok{PlantDat2[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{),]}
\NormalTok{PlantDat2 <-}\StringTok{ }\NormalTok{PlantDat2[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{),]}
\NormalTok{PlantDat2 <-}\StringTok{ }\NormalTok{PlantDat2[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{),]}
\NormalTok{PlantDat2 <-}\StringTok{ }\NormalTok{PlantDat2[}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{),]}
\NormalTok{PlantDat2}\OperatorTok{$}\NormalTok{treatment <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(PlantDat2}\OperatorTok{$}\NormalTok{treatment)}
\NormalTok{con1=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{,}\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{, }\OperatorTok{-}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\NormalTok{con2=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\OperatorTok{-}\NormalTok{.}\DecValTok{5}\NormalTok{, }\OperatorTok{-}\NormalTok{.}\DecValTok{5}\NormalTok{)}
\NormalTok{con3=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, }\OperatorTok{-}\DecValTok{1}\NormalTok{)}
\NormalTok{cons2=}\KeywordTok{cbind}\NormalTok{(con1,con2, con3)}

\KeywordTok{rownames}\NormalTok{(cons2)}\OperatorTok{<=}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## logical(0)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(cons2) }\OperatorTok{%*%}\StringTok{ }\NormalTok{cons2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          con1 con2 con3
## con1 1.333333  0.0    0
## con2 0.000000  1.5    0
## con3 0.000000  0.0    2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{contrasts}\NormalTok{(PlantDat2}\OperatorTok{$}\NormalTok{treatment) =}\StringTok{ }\NormalTok{cons2}
\CommentTok{#Now run your ANOVA}
\NormalTok{plant2.lm<-}\KeywordTok{lm}\NormalTok{(vigor}\OperatorTok{~}\KeywordTok{C}\NormalTok{(treatment,con1,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,con2,}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\KeywordTok{C}\NormalTok{(treatment,con3,}\DecValTok{1}\NormalTok{), }\DataTypeTok{data=}\NormalTok{PlantDat2)}
\KeywordTok{Anova}\NormalTok{(plant2.lm, }\DataTypeTok{type=}\StringTok{"III"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Anova Table (Type III tests)
## 
## Response: vigor
##                        Sum Sq Df  F value    Pr(>F)    
## (Intercept)           208.803  1 120.1741 1.316e-07 ***
## C(treatment, con1, 1)  36.401  1  20.9501 0.0006356 ***
## C(treatment, con2, 1)   1.602  1   0.9218 0.3559437    
## C(treatment, con3, 1)  10.125  1   5.8273 0.0326741 *  
## Residuals              20.850 12                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aov2.cons <-}\StringTok{ }\KeywordTok{aov}\NormalTok{(vigor }\OperatorTok{~}\StringTok{ }\NormalTok{treatment, }\DataTypeTok{data =}\NormalTok{ PlantDat2)}
\CommentTok{#Good Luck following this next funky command to get the proper ANOVA table with the orthogonal contrasts included!}
\CommentTok{#Note the second list names your contrasts in the order you entered them into Cons}
\KeywordTok{summary}\NormalTok{(aov2.cons, }\DataTypeTok{split=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{treatment=}\KeywordTok{list}\NormalTok{(}\StringTok{"no removal vs removal"}\NormalTok{=}\DecValTok{1}\NormalTok{, }\StringTok{"hand vs regulator"}\NormalTok{=}\DecValTok{2}\NormalTok{,}\StringTok{"g1 vs g2"}\NormalTok{=}\DecValTok{3}\NormalTok{)), }\DataTypeTok{type=}\StringTok{"III"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                    Df Sum Sq Mean Sq F value   Pr(>F)    
## treatment                           3  48.13   16.04   9.233 0.001925 ** 
##   treatment: no removal vs removal  1  36.40   36.40  20.950 0.000636 ***
##   treatment: hand vs regulator      1   1.60    1.60   0.922 0.355944    
##   treatment: g1 vs g2               1  10.13   10.13   5.827 0.032674 *  
## Residuals                          12  20.85    1.74                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{50.401}\OperatorTok{+}\FloatTok{2.059}\OperatorTok{+}\FloatTok{10.125}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 62.585
\end{verbatim}

Now the Sum Sq for each treatment sum to be equal to the sum Sq of
treatment as 36.40+1.60+10.13=48.13. I am not surprised by the results
as not each treatment has the same number of observations. These are
orthogonal as each treatmetn group has the same number of units thus,
they are now orthogonal.


\end{document}
